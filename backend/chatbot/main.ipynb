{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7eb77990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelLoaderManager initialized. Detected device: CUDA\n",
      "All necessary modules imported and nest_asyncio applied.\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Imports and nest_asyncio setup\n",
    "\n",
    "import os\n",
    "import asyncio\n",
    "import torch\n",
    "\n",
    "# --- Import your configuration ---\n",
    "import config\n",
    "\n",
    "# --- Import the globally accessible AudioManager and ModelLoaderManager instances ---\n",
    "from AudioManager import audio_manager\n",
    "from ModelLoaderManager import model_loader_manager\n",
    "# Import the new CommandLineMenu class\n",
    "from CommandLineMenu import CommandLineMenu\n",
    "\n",
    "# Important for running asyncio multiple times in a notebook cell\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "print(\"All necessary modules imported and nest_asyncio applied.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9e995a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting model and audio manager initialization...\n",
      "Created directories: /home/olexandro/NLP/vocal-chatbot-grag-quote-assistant/storage/audio/audio_recordings, /home/olexandro/NLP/vocal-chatbot-grag-quote-assistant/storage/audio/speaker_embeddings\n",
      "Initializing all NeMo models via ModelLoaderManager...\n",
      "\n",
      "--- Starting Model Loading Process ---\n",
      "Attempting to load pre-trained Speaker Verification model (TitaNet-Large)...\n",
      "[NeMo I 2025-07-05 09:48:38 cloud:58] Found existing object /home/olexandro/.cache/torch/NeMo/NeMo_2.0.0rc0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n",
      "[NeMo I 2025-07-05 09:48:38 cloud:64] Re-using file from: /home/olexandro/.cache/torch/NeMo/NeMo_2.0.0rc0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo\n",
      "[NeMo I 2025-07-05 09:48:38 common:815] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-05 09:48:39 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/train.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 64\n",
      "    shuffle: true\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    tarred_shard_strategy: scatter\n",
      "    augmentor:\n",
      "      noise:\n",
      "        manifest_path: /manifests/noise/rir_noise_manifest.json\n",
      "        prob: 0.5\n",
      "        min_snr_db: 0\n",
      "        max_snr_db: 15\n",
      "      speed:\n",
      "        prob: 0.5\n",
      "        sr: 16000\n",
      "        resample_type: kaiser_fast\n",
      "        min_speed_rate: 0.95\n",
      "        max_speed_rate: 1.05\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n",
      "[NeMo W 2025-07-05 09:48:39 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: /manifests/combined_fisher_swbd_voxceleb12_librispeech/dev.json\n",
      "    sample_rate: 16000\n",
      "    labels: null\n",
      "    batch_size: 128\n",
      "    shuffle: false\n",
      "    num_workers: 15\n",
      "    pin_memory: true\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-05 09:48:39 features:305] PADDING: 16\n",
      "[NeMo I 2025-07-05 09:48:40 save_restore_connector:263] Model EncDecSpeakerLabelModel was successfully restored from /home/olexandro/.cache/torch/NeMo/NeMo_2.0.0rc0/titanet-l/11ba0924fdf87c049e339adbf6899d48/titanet-l.nemo.\n",
      "Successfully loaded pre-trained TitaNet-Large model.\n",
      "\n",
      "Attempting to load ASR model (FastConformer-Large)...\n",
      "[NeMo I 2025-07-05 09:48:41 mixins:172] Tokenizer SentencePieceTokenizer initialized with 1024 tokens\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-05 09:48:42 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 1\n",
      "    shuffle: true\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    trim_silence: false\n",
      "    max_duration: 20\n",
      "    min_duration: 0.1\n",
      "    is_tarred: false\n",
      "    tarred_audio_filepaths: null\n",
      "    shuffle_n: 2048\n",
      "    bucketing_strategy: fully_randomized\n",
      "    bucketing_batch_size: null\n",
      "    \n",
      "[NeMo W 2025-07-05 09:48:42 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 32\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    max_duration: 20\n",
      "    \n",
      "[NeMo W 2025-07-05 09:48:42 modelPT:189] Please call the ModelPT.setup_test_data() or ModelPT.setup_multiple_test_data() method and provide a valid configuration file to setup the test data loader(s).\n",
      "    Test config : \n",
      "    manifest_filepath: null\n",
      "    sample_rate: 16000\n",
      "    batch_size: 16\n",
      "    shuffle: false\n",
      "    num_workers: 8\n",
      "    pin_memory: true\n",
      "    use_start_end_token: false\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-05 09:48:42 features:305] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-05 09:48:42 nemo_logging:349] /home/olexandro/NLP/vocal-chatbot-grag-quote-assistant/.venv/lib/python3.10/site-packages/torch/nn/modules/rnn.py:82: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "      warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-05 09:48:43 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n",
      "[NeMo I 2025-07-05 09:48:43 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-05 09:48:43 rnnt_loop_labels_computer:270] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: No `cuda-python` module. Please do `pip install cuda-python>=12.3`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-05 09:48:43 rnnt_models:224] Using RNNT Loss : warprnnt_numba\n",
      "    Loss warprnnt_numba_kwargs: {'fastemit_lambda': 0.0, 'clamp': -1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-05 09:48:43 rnnt_loop_labels_computer:270] No conditional node support for Cuda.\n",
      "    Cuda graphs with while loops are disabled, decoding speed will be slower\n",
      "    Reason: No `cuda-python` module. Please do `pip install cuda-python>=12.3`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-05 09:48:44 save_restore_connector:263] Model EncDecRNNTBPEModel was successfully restored from /home/olexandro/.cache/huggingface/hub/models--nvidia--stt_en_fastconformer_transducer_large/snapshots/24a0e16aa9ebfb00b61300514c89cd84a4950021/stt_en_fastconformer_transducer_large.nemo.\n",
      "Successfully loaded ASR model from HuggingFace.\n",
      "\n",
      "Attempting to load FastPitch TTS model...\n",
      "[NeMo I 2025-07-05 09:48:44 cloud:58] Found existing object /home/olexandro/.cache/torch/NeMo/NeMo_2.0.0rc0/tts_en_fastpitch_align/b7d086a07b5126c12d5077d9a641a38c/tts_en_fastpitch_align.nemo.\n",
      "[NeMo I 2025-07-05 09:48:44 cloud:64] Re-using file from: /home/olexandro/.cache/torch/NeMo/NeMo_2.0.0rc0/tts_en_fastpitch_align/b7d086a07b5126c12d5077d9a641a38c/tts_en_fastpitch_align.nemo\n",
      "[NeMo I 2025-07-05 09:48:44 common:815] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " NeMo-text-processing :: INFO     :: Creating ClassifyFst grammars.\n",
      "[NeMo W 2025-07-05 09:49:06 en_us_arpabet:66] apply_to_oov_word=None, This means that some of words will remain unchanged if they are not handled by any of the rules in self.parse_one_word(). This may be intended if phonemes and chars are both valid inputs, otherwise, you may see unexpected deletions in your input.\n",
      "[NeMo W 2025-07-05 09:49:06 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.torch.data.TTSDataset\n",
      "      manifest_filepath: /ws/LJSpeech/nvidia_ljspeech_train_clean_ngc.json\n",
      "      sample_rate: 22050\n",
      "      sup_data_path: /raid/LJSpeech/supplementary\n",
      "      sup_data_types:\n",
      "      - align_prior_matrix\n",
      "      - pitch\n",
      "      n_fft: 1024\n",
      "      win_length: 1024\n",
      "      hop_length: 256\n",
      "      window: hann\n",
      "      n_mels: 80\n",
      "      lowfreq: 0\n",
      "      highfreq: 8000\n",
      "      max_duration: null\n",
      "      min_duration: 0.1\n",
      "      ignore_file: null\n",
      "      trim: false\n",
      "      pitch_fmin: 65.40639132514966\n",
      "      pitch_fmax: 2093.004522404789\n",
      "      pitch_norm: true\n",
      "      pitch_mean: 212.35873413085938\n",
      "      pitch_std: 68.52806091308594\n",
      "      use_beta_binomial_interpolator: true\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: true\n",
      "      batch_size: 24\n",
      "      num_workers: 0\n",
      "    \n",
      "[NeMo W 2025-07-05 09:49:06 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.torch.data.TTSDataset\n",
      "      manifest_filepath: /ws/LJSpeech/nvidia_ljspeech_val_clean_ngc.json\n",
      "      sample_rate: 22050\n",
      "      sup_data_path: /raid/LJSpeech/supplementary\n",
      "      sup_data_types:\n",
      "      - align_prior_matrix\n",
      "      - pitch\n",
      "      n_fft: 1024\n",
      "      win_length: 1024\n",
      "      hop_length: 256\n",
      "      window: hann\n",
      "      n_mels: 80\n",
      "      lowfreq: 0\n",
      "      highfreq: 8000\n",
      "      max_duration: null\n",
      "      min_duration: null\n",
      "      ignore_file: null\n",
      "      trim: false\n",
      "      pitch_fmin: 65.40639132514966\n",
      "      pitch_fmax: 2093.004522404789\n",
      "      pitch_norm: true\n",
      "      pitch_mean: 212.35873413085938\n",
      "      pitch_std: 68.52806091308594\n",
      "      use_beta_binomial_interpolator: true\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 24\n",
      "      num_workers: 0\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-05 09:49:06 features:305] PADDING: 1\n",
      "[NeMo I 2025-07-05 09:49:06 save_restore_connector:263] Model FastPitchModel was successfully restored from /home/olexandro/.cache/torch/NeMo/NeMo_2.0.0rc0/tts_en_fastpitch_align/b7d086a07b5126c12d5077d9a641a38c/tts_en_fastpitch_align.nemo.\n",
      "Successfully loaded FastPitch TTS model.\n",
      "\n",
      "Attempting to load HiFi-GAN vocoder model...\n",
      "[NeMo I 2025-07-05 09:49:08 cloud:58] Found existing object /home/olexandro/.cache/torch/NeMo/NeMo_2.0.0rc0/tts_hifigan/e6da322f0f7e7dcf3f1900a9229a7e69/tts_hifigan.nemo.\n",
      "[NeMo I 2025-07-05 09:49:08 cloud:64] Re-using file from: /home/olexandro/.cache/torch/NeMo/NeMo_2.0.0rc0/tts_hifigan/e6da322f0f7e7dcf3f1900a9229a7e69/tts_hifigan.nemo\n",
      "[NeMo I 2025-07-05 09:49:08 common:815] Instantiating model from pre-trained checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-05 09:49:23 modelPT:176] If you intend to do training or fine-tuning, please call the ModelPT.setup_training_data() method and provide a valid configuration file to setup the train data loader.\n",
      "    Train config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.data.datalayers.MelAudioDataset\n",
      "      manifest_filepath: /home/fkreuk/data/train_finetune.txt\n",
      "      min_duration: 0.75\n",
      "      n_segments: 8192\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: true\n",
      "      batch_size: 64\n",
      "      num_workers: 4\n",
      "    \n",
      "[NeMo W 2025-07-05 09:49:23 modelPT:183] If you intend to do validation, please call the ModelPT.setup_validation_data() or ModelPT.setup_multiple_validation_data() method and provide a valid configuration file to setup the validation data loader(s). \n",
      "    Validation config : \n",
      "    dataset:\n",
      "      _target_: nemo.collections.tts.data.datalayers.MelAudioDataset\n",
      "      manifest_filepath: /home/fkreuk/data/val_finetune.txt\n",
      "      min_duration: 3\n",
      "      n_segments: 66150\n",
      "    dataloader_params:\n",
      "      drop_last: false\n",
      "      shuffle: false\n",
      "      batch_size: 5\n",
      "      num_workers: 4\n",
      "    \n",
      "[NeMo W 2025-07-05 09:49:24 features:282] Using torch_stft is deprecated and has been removed. The values have been forcibly set to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-05 09:49:24 features:305] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-05 09:49:24 features:282] Using torch_stft is deprecated and has been removed. The values have been forcibly set to False for FilterbankFeatures and AudioToMelSpectrogramPreprocessor. Please set exact_pad to True as needed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-05 09:49:24 features:305] PADDING: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2025-07-05 09:49:25 nemo_logging:349] /home/olexandro/NLP/vocal-chatbot-grag-quote-assistant/.venv/lib/python3.10/site-packages/torch/nn/utils/weight_norm.py:30: UserWarning: torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\n",
      "      warnings.warn(\"torch.nn.utils.weight_norm is deprecated in favor of torch.nn.utils.parametrizations.weight_norm.\")\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2025-07-05 09:49:53 save_restore_connector:263] Model HifiGanModel was successfully restored from /home/olexandro/.cache/torch/NeMo/NeMo_2.0.0rc0/tts_hifigan/e6da322f0f7e7dcf3f1900a9229a7e69/tts_hifigan.nemo.\n",
      "Successfully loaded HiFi-GAN vocoder model.\n",
      "--- All Models Loading Process Completed ---\n",
      "NeMo models initialized successfully.\n",
      "Initializing AudioManager...\n",
      "Initializing AudioManager...\n",
      "Warning: Speaker verification model not provided during AudioManager initialization.\n",
      "AudioManager initialized successfully.\n",
      "AudioManager initialized successfully.\n",
      "Models are now loaded and ready in memory.\n"
     ]
    }
   ],
   "source": [
    "# Cell 2: Model and Audio Manager Initialization (Run ONCE)\n",
    "\n",
    "print(\"Starting model and audio manager initialization...\")\n",
    "\n",
    "# Ensure necessary directories are created at startup\n",
    "os.makedirs(config.AUDIO_RECORDINGS_DIR, exist_ok=True)\n",
    "os.makedirs(config.EMBEDDING_OUTPUT_DIR, exist_ok=True)\n",
    "print(f\"Created directories: {config.AUDIO_RECORDINGS_DIR}, {config.EMBEDDING_OUTPUT_DIR}\")\n",
    "\n",
    "# --- STEP 1: Initialize ModelLoaderManager ONCE ---\n",
    "print(\"Initializing all NeMo models via ModelLoaderManager...\")\n",
    "model_loader_manager.initialize_all_models()\n",
    "print(\"NeMo models initialized successfully.\")\n",
    "\n",
    "# --- STEP 2: Initialize AudioManager ONCE with models from ModelLoaderManager ---\n",
    "print(\"Initializing AudioManager...\")\n",
    "audio_manager.initialize(\n",
    "    asr_model=model_loader_manager.asr_model,\n",
    "    tts_model=model_loader_manager.tts_model,\n",
    "    vocoder_model=model_loader_manager.vocoder_model,\n",
    "    sample_rate=config.TTS_SAMPLE_RATE, # Changed from config.SAMPLE_RATE as per our discussion\n",
    "    recording_duration_seconds=config.RECORDING_DURATION_SECONDS,\n",
    "    audio_records_dir=config.AUDIO_RECORDINGS_DIR,\n",
    "    use_tts_for_answers_flag=config.USE_TTS_FOR_ANSWERS\n",
    ")\n",
    "print(\"AudioManager initialized successfully.\")\n",
    "\n",
    "print(\"Models are now loaded and ready in memory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7e0a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting new interactive menu session ---\n",
      "Ollama client initialized with default model 'deepseek-r1:1.5b'.\n",
      "Using internal _default_ollama_call for LLM interactions.\n",
      "Welcome to the Vocal Chatbot!\n",
      "(Speaking response...)\n",
      "NOTICE: Text to speech for computer answers is currently **enabled**.\n",
      "\n",
      "==================================================\n",
      "VOCAL CHATBOT SYSTEM MENU\n",
      "==================================================\n",
      "1. Register a new speaker\n",
      "2. Authenticate User (Voice Identification)\n",
      "3. Start Voice Chat (Authenticated)\n",
      "4. Conversational Neo4j Query (Fully Vocal)\n",
      "5. Transcribe an audio file (ASR only)\n",
      "6. Convert an existing audio file to embedding\n",
      "7. Synthesize speech from text (TTS only)\n",
      "8. List all registered speaker embeddings\n",
      "9. Delete a registered speaker embedding\n",
      "10. Clear ALL registered speaker embeddings\n",
      "11. Toggle TTS for computer answers (Currently: ENABLED)\n",
      "0. Exit\n",
      "==================================================\n",
      "Please speak your choice from the menu.\n",
      "(Speaking response...)\n",
      "\n",
      "--- Starting Audio Recording Setup ---\n",
      "Please speak your menu choice (e.g., 'one', 'two', 'exit') for 3 seconds.\n",
      "Using input device: default (ID: 1)\n",
      "Invalid input. Recording not started. Please try again.\n",
      "No audio recorded for menu choice. Please try again.\n",
      "(Speaking response...)\n",
      "\n",
      "==================================================\n",
      "VOCAL CHATBOT SYSTEM MENU\n",
      "==================================================\n",
      "1. Register a new speaker\n",
      "2. Authenticate User (Voice Identification)\n",
      "3. Start Voice Chat (Authenticated)\n",
      "4. Conversational Neo4j Query (Fully Vocal)\n",
      "5. Transcribe an audio file (ASR only)\n",
      "6. Convert an existing audio file to embedding\n",
      "7. Synthesize speech from text (TTS only)\n",
      "8. List all registered speaker embeddings\n",
      "9. Delete a registered speaker embedding\n",
      "10. Clear ALL registered speaker embeddings\n",
      "11. Toggle TTS for computer answers (Currently: ENABLED)\n",
      "0. Exit\n",
      "==================================================\n",
      "Please speak your choice from the menu.\n",
      "(Speaking response...)\n",
      "\n",
      "--- Starting Audio Recording Setup ---\n",
      "Please speak your menu choice (e.g., 'one', 'two', 'exit') for 3 seconds.\n",
      "Using input device: default (ID: 1)\n",
      "\n",
      "Recording started for 3 seconds...\n",
      "Recording finished.\n",
      "Temporary audio saved to: /home/olexandro/NLP/vocal-chatbot-grag-quote-assistant/storage/audio/audio_recordings/menu_choice_temp.wav\n",
      "\n",
      "--- Starting ASR Transcription for 'menu_choice_temp.wav' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 100%|██████████| 1/1 [00:02<00:00,  2.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Transcription is: \"four\"\n",
      "(Speaking response...)\n",
      "The Transcription is: \"four\"\n",
      "Cleaned up temporary menu audio: /home/olexandro/NLP/vocal-chatbot-grag-quote-assistant/storage/audio/audio_recordings/menu_choice_temp.wav\n",
      "User's spoken choice (transcribed): four -> Processed Choice: 4\n",
      "What's your initial question for the knowledge graph?\n",
      "(Speaking response...)\n",
      "You can say 'root' at any time to go back to the main menu.\n",
      "(Speaking response...)\n",
      "\n",
      "--- Starting Audio Recording Setup ---\n",
      "Speak your initial question (or 'root') for 3 seconds.\n",
      "Using input device: default (ID: 1)\n",
      "\n",
      "Recording started for 3 seconds...\n",
      "Recording finished.\n",
      "Temporary audio saved for processing: /home/olexandro/NLP/vocal-chatbot-grag-quote-assistant/storage/audio/audio_recordings/temp_vocal_input.wav\n",
      "\n",
      "--- Starting ASR Transcription for 'temp_vocal_input.wav' ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Transcribing: 100%|██████████| 1/1 [00:00<00:00,  4.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Transcription is: \"peer dismissed the last stage of capitalism\"\n",
      "(Speaking response...)\n",
      "Cleaned up temporary audio: /home/olexandro/NLP/vocal-chatbot-grag-quote-assistant/storage/audio/audio_recordings/temp_vocal_input.wav\n",
      "Processing your question...\n",
      "(Speaking response...)\n",
      "Successfully connected to Neo4j.\n",
      "Neo4j driver closed.\n",
      "\n",
      "--- Chatbot: Error: Ollama response structure was unexpected or content was empty.\n",
      "(Speaking response...)\n",
      "Would you like to know more about it?\n",
      "(Speaking response...)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Start Interactive Menu (Re-run for new chatbot sessions)\n",
    "\n",
    "print(\"\\n--- Starting new interactive menu session ---\")\n",
    "\n",
    "# Create an instance of CommandLineMenu and start it\n",
    "# The CommandLineMenu now encapsulates the interactive loop\n",
    "# and the ConversationalNeo4jChatbot handles its own LLM calls.\n",
    "# It will use the pre-loaded models from audio_manager.\n",
    "menu = CommandLineMenu()\n",
    "await menu.start_interactive_menu()\n",
    "\n",
    "print(\"\\n--- Interactive menu session ended. ---\")\n",
    "# You can now run this cell again to start a new session without reloading models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
